# cs245e - Logic and Computation Enriched | Fall 2020
The course will be based off the textbook LACI by Professor Ragde

# Chapter 1 - Introduction

Racket knowledge is a prerequisite of this course

# Chapter 2 - Propositional logic

Here are some **grammar** rules: 
1. if $n$ is an integer, then $n$ is an arithmetic expression. 
2. if $E_1$ and $E_2$ are arithmetic expressions, then ($E_1 + E_2)$ is an arithmetic expression
3. if $E_1$ and $E_2$ are arithmetic expressions, then ($E_1 \cdot E_2$) is an arithmetic expression

Each of these rules has a **conclusions** that is drawn from some **premises**.         
Such rules are called **inference rule**s

We can abbreviate by using a horizontal line where the top is the premise and below is the conclusion           
$\frac{n \in \mathbb{Z}}{n \in \varepsilon}$, $\frac{E_1 \in \varepsilon E_2 \in \varepsilon}{(E_1 + E_2) \in \varepsilon}$, 

We can chain **inferences** to form a tree such that many premises lead to eventually one conclusion.           

## Chapter 2.1 - Formulas

The formulas we study will use **logical connectives**. They resemble arithmetic expressions. 
- and/conjuction : $\wedge$
- if-then/implication : $\Rightarrow$ or $\rightarrow$
- or/disjunction : $\vee$
- not/negation: $\neg$

we also use propsitional variables, $A, B, C, \cdots$ which represent statements or atomic propositions             
(assertions that must be true or false). Together with the logical connectives they make the language of **propositional logic**

$A \iff B$ can be represented with $(A \rightarrow B) \wedge (B \rightarrow A)$

Here is the grammar of propositional formulas we will use for now (will change as we go).       
T = X       
    | 	(T ∧ T)     
    | 	(T ∨ T)     
    | 	(¬ T)       
    | 	(T → T)     
- X is a **metavariable** since it ranges over other variables
- The grammar states that any variables X is a propositional variable
-   any and, or, negation, implication of two variables is also a propositional variable

For formulas, the priority goes, Negation -> conjuction/disjunction (left-associativity) -> implication

## Chapter 2.2 - The Boolean interpretation

We will use 1 and 0 to represent the "true" and "false" values known as **Boolean Values** which form **Boolean algebra**.      

We will use a Boolean interpretation by assigning our logical variables to Boolean values and considering the formula to be true,       
when any possible Boolean assignment evaluates to true.         

$$\begin{align*}
\langle X \rangle_v &= v(X), ~X\mbox{ a variable}\\ \langle T \land V \rangle_v &= \langle T \rangle_v \land \langle V \rangle_v \\ \langle T \lor V \rangle_v &= \langle T \rangle_v \lor \langle V \rangle_v \\ \langle T \ra V \rangle_v &= \langle T \rangle_v \ra \langle V \rangle_v \\ \langle \lnot T \rangle_v &= \lnot \langle T \rangle_v
\end{align*}$$
<ScrollWheelDown>We use a **valuation** v, which is a map/function from propoisiton variables to the Boolean values {0, 1}.      
For connectives with the recursive definition for $\langle T \rangle_v$ which is the truth value assigned to formula $T$ by valuation $v$. 

To check whether a formula is true we have to try every possible combination of values, which results in exponential number of calculations.        
So we will continue to develop the idea of proof this chapter to prove formulas without having to go through a full truth table.

There are two ways that proof and truth are related. 
1. **soundness:** "if a formula has a proof, then it is true" or the contrapositive "if a formula is not true, then it has no proof"
    - this will be the interpretation we use
2. **completeness:** "if a formula is true, then it has a proof"

## Chapter 2.3 - Proof for the implicational fragment

We start by restricting the language of formulas to only propositional variables and implication. 
T = X
| (T -> T)

We write $\Gamma\vdash T$ to mean "From the assumption $\Gamma$, we can prove $T$. 
- A statement of this form is called a **sequent** 
- $\Gamma$ is called the **context**
- the symbol $\vdash$ is called "turnstile"

We will use a system called **natural deduction** introduced by Gerhard Gentzen

First rule in our set of inference rules for natural deduction: 
$\frac{\Gamma, T \vdash W}{\Gamma \vdash T \rightarrow W} (\rightarrow I)$
- $(\rightarrow I)$ means implication introduction (\rightarrow I)$

Second rule
$\frac{\Gamma \vdash T \rightarrow W \Gamma \vdash T}{\Gamma \vdash W} (\rightarrow E)$
- $\rightarrow E$ means implication elimination

Assumptions:        
$\frac{T \in \Gamma}{\Gamma \vdash T} (Ass)$
- (Ass) for assumption 
Here is a better way to make this rule clear that its an **axiom**:         
$\frac{}{\Gamma, T \vdash T} (Ass)$

## Chapter 2.4 - Proofs as programs

We want to interpret logical connectives in terms of what a proof of a formula using that connective should look like.          
This idea is the basis of the **BHK interpretation** which we will be using thruoghout the rest of the course.          

The BHK interpretation for implication is phrased as "A proof of $\T \rightarrow W$ is a construction which permits us to       
transform a proof of $T$ into a proof of $W$".
-   the word construction could be interpreted in many ways, we will interpret it as meaning a function
t = x       
| ($\lambda$x.t)
| (t t)

We change our sequent notation to include proof terms. A sequent is now a three way relation $\Gamma \vdash t : T$,         
this reads as "$\Gamma$ proves $T$ with proof $t$"          
Here is the rule for implication introduction:      
$\frac{\Gamma, x : T \vdash t : W}{\Gamma \vdash \lambda x.t : T \rightarrow W} (\rightarrow I)$            

$\frac{\Gamma \vdash f : T \rightarrow W \Gamma \vdash a : T}{\Gamma \vdash f a : W} (\rightarrow E)$
- implication elimination

$\frac{}{\Gamma, x : T \vdash x : T} (Var)$
- we change the rule for assumptions to be called "Var"

we can write the proof term for $A \rightarrow B \rightarrow A$ as          
$\vdash \lambda x.\lambda y.x : A \rightarrow B \rightarrow A$        
and for $A \rightarrow ((A \rightarrow B) \rightarrow B)$:      
$\vdash \lambda x.\lambda f.f x : A \rightarrow ((A \rightarrow B) \rightarrow B)$

## Supplementary material - List abbreviations and pattern matching 

Quote notation in racket: 
```Scheme
'(1 x 2)
```
- in this code the x becomes the symbol x, but what if we wanted x as a variable?           
we would need: 
```Scheme
(list 1 x 2)
```
- quote notation turns any identifier or variable looking thing to a symbol i.e `'*`

Here's an example of an interpreter 
```Scheme
(define (interp exp)
    (cond 
        [(number? exp) exp]
        [(symbol=? (first exp) '*)
            (* (interp (second exp))
               (interp (third exp)))]
        [(symbol=? (first exp) '+)
            (+ (interp (second exp))
               (interp (third exp)))])) 
```
with `(interp '(* (+ 1 2) (+ 3 4)))` evaluating to 21

we can achieve this using **Quasiquoute** abbreviated with a single open quote \`
- this allows us to escape Racket expressions, if we don't use any escapes it behaves like quote. 
- escapes are abbreviated with a comma

```Scheme
(define x 3)

`(a b ,(+ 2 x))
=> '(a b 5)
```

we can use **unquote-splicing** to splice a list of elements: 
- abbreviated with ,@
```Scheme
(define x '(c d))

`(a b ,@x)
=> '(a b c d)
```

A useful pattern-matching speciam form `match` is available in full Racket. 
- it maches `cond` but there is an initial expression which is reduced to a value and the questiosn     
are replaced by patterns against whcih the value is matched 

```Scheme 
(match exp
    [pattern answer]
    ...)

(define (f x) 
    (match x
        [y (+ 3 y)]))
(f 2) => 5
(f 5) => 8

(define (f x)
    (match x 
        [3 "three"]
        ["four" 4]
        [y false]))
(f 3) => "three"
(f "four") => 4
(f 5) => false
```
- an identifier by itself is a pattern that matches any value
- numbers and strings are patterns matching their values

We can form compound patterns by applying list to a sequence of several patterns. 
```Scheme
(define (f x)
    (match x
        [(list x y) (+ x y)]
        [(list x y rst ...)
            (list (- x y) rst)]
        [(list 1) false]))

(f '(1 2)) => 3
(f '(1 2 3 4)) => '(-1 (3 4))
(f '(1)) => false
```
Identifiers can be repeated in a pattern indicating a reptition of a value in whatever matches.             

```Scheme
(define (g x)
    (match x
        [(list x y x) (+ x y)]
        [(list (list x y) z ) (- x z)] 
        ['(1 (2 3)) true]))

(g '(1 3 1)) => 4
(g '((4 8) 3)) => 1
(g '(1 (2 3))) => true
```

Patterns can use `cons` and `list`, an `_` underscore can be used to indicate the presence of a value that we don't need to a give a name       
structures can also be used in patterns. 

```Scheme 
(struct posn (x y))
(define (h x)
    (match x
        [(cons 1 (list y z)) (+ y z)]
        [(list p _) (sqr p)]
        [(posn p q)
            (lsit p q)]))

(h '(1 2 3)) => 5
(h '(2 3)) => 4
(h (posn 7 8)) => (list 7 8)
```

Quasiquote also works in pattern matching. 
```Scheme 
(define (h x)
  (match x
    [`(1 ,y ,z) (+ y z)]
    [`(,(posn p q) ,r)
        (list p q r)]
    [`(,p ,_) (sqr p)]))
(h '(1 2 3)) => 5
(h (list (posn 7 8) 9))  => '(7 8 9)
(h ('3 4)) => 9
```

Here's an example of our interpreter using match, 
```Scheme
;; original (without using match)
(define (interp exp)
  (cond
    [(number? exp) exp]
    [(symbol=? (first exp) '*)
       (* (interp (second exp))
          (interp (third exp)))]
    [(symbol=? (first exp) '+)
       (+ (interp (second exp))
          (interp (third exp)))]))

;; with match
(define (interp exp)
  (match exp
    [(? number? n) n]
    [`(* ,x ,y) (* (interp x) (interp y))]
    [`(+ ,x ,y) (+ (interp x) (interp y))]))
```
- the first pattern using ? applies the predicate `number?` to the value

## Chapter 2.5 - Proust for implication

Our goal is write a Racket function that validates a sequent $\Gamma \vdash t : T$           

We start with the goal of verifying the sequent, let's write this goal as       
$\Gamma \vdash t \Leftarrow T$ and call it **type checking**.       

The other task we have is when we only have two of the pieces, the context $T$ and the term $t$         
and from them we need to figure out the type $T$. Let's write this goal as $\Gamma \vdash t \Rightarrow T$ and call it      
**type snythesis**.         
- this approach is known as bidirectional typing and is used in real compilers
kJ:w

Here are the modified inference rules:      
$$\frac{ \Gamma, x : T \vdash t \Leftarrow W}{\Gamma \vdash \lambda x . t \Leftarrow T \rightarrow W} (\rightarrow I)$$
$$\frac{ \Gamma \vdash f \Rightarrow T \rightarrow W \Gamma \vdash a \Leftarrow T}{\Gamma \vdash f a \Rightarrow W} (\rightarrow E)$$
$$\frac{}{\Gamma, x : X \vdash x \Rightarrow X} (Var)$$


We can turn from checking to synthesis using the following rule,        
$$\frac{\Gamma \vdash t \Rightarrow T}{\Gamma \vdash t \Leftarrow T}(Turn)$$ 
or
$$\frac{\Gamma \vdash t \Rightarrow T' T \equiv T'}{\Gamma \vdash t \Leftarrow T} (Turn)$$

We introduce a grammar rule for terms with a type annotation (which helps us check things that need synthesis)      

t = x           
| ($\lambda$ x.t)           
| (t t)         
| (t : T)           

Here is the grammar for types and expressions (terms) in Prous: 
expr = ($\lambda$ x => expr) 
    | (expr expr)
    | (expr : type) 
    | x 

type = (type -> type)
    | X 

Here are the Racket `struct`s for each grammar rule
```Scheme
(struct Lam (var body) #:transparent)
(struct App (rator rand) #:transparent)
(struct Ann (expr type) #:transparent)

(struct Arrow (domain range) #:transparent)
```

The parser: 
```Scheme
;; parse-expr : sexp -> Expr
;; sexp = symbolic expression

(define (parse-expr s) 
    (match s 
        [`(λ ,(? symbol? x) => ,e) (Lam x (parse-expr e))]
        [`(,e1, ,e2) (App (parse-expr e1) (parse-expr e2))]
        [(? symbol? x) x]
        [`(,e : ,t) (Ann (parse-expr e) (parse-type t))]
        [else (error 'parse "bad syntax: ~a" s)]))

;; parse-type : sexp -> Type

(define (parse-type t)
    (match t
        [`(,t1 -> ,t2) (Arrow (parse-type t1) (parse-type t2))]
        [(? symbol? X) X]
        [else (error 'parse "bad syntax: ~a\n" t)]))
```
Here are lines to add which allow for left-associative function application and right-associative arrows.       
```Scheme
;; added to the end of parse-expr
[`(,e1 ,e2 ,e3 ,r ...) (parse-expr `((,e1 ,e2) ,e3 ,@r))]

;; added to parse-type
[`(,t1 -> ,t2 -> ,r ...) (Arrow (parse-type t1) (parse-type `(,t2 -> ,@r)))]
```

Here are functions which create readable strings for humans from the abstract structures:           
```Scheme 

; pretty-print-expr : Expr -> String
 
(define (pretty-print-expr e)
  (match e
    [(Lam x b) (format "(λ ~a => ~a)" x (pretty-print-expr b))]
    [(App e1 e2) (format "(~a ~a)" (pretty-print-expr e1)
                                   (pretty-print-expr e2))]
    [(? symbol? x) (format "~a" x)]
    [(Ann e t) (format "(~a : ~a)" (pretty-print-expr e)
                                   (pretty-print-type t))]))
 
; pretty-print-type : Type -> String
 
(define (pretty-print-type t)
  (match t
    [(Arrow t1 t2) (format "(~a -> ~a)" (pretty-print-type t1)
                                        (pretty-print-type t2))]
    [else (symbol->string t)]))
```

```Scheme

; type-check : Context Expr Type -> boolean
; produces true if expr has type t in context ctx (or error if not)
 
(define (type-check ctx expr type)
  (match expr
    [(Lam x t)
       (match type
         [(Arrow tt tw) (type-check (cons `(,x ,tt) ctx) t tw)]
         [else (cannot-check ctx expr type)])]
    [else (if (equal? (type-synth ctx expr) type) true (cannot-check ctx expr type))]))
 
; type-synth : Context Expr -> Type
; produces type of expr in context ctx (or error if can't)
; all failing cases spelled out rather than put into "else" at end
 
(define (type-synth ctx expr)
  (match expr
    [(Lam _ _) (cannot-synth ctx expr)]
    [(Ann e t) (type-check ctx e t) t]
    [(App f a)
       (define tf (type-synth ctx f))
        (match tf
         [(Arrow tt tw) #:when (type-check ctx a tt) tw]
         [else (cannot-synth ctx expr)])]
    [(? symbol? x)
       (cond
         [(assoc x ctx) => second]
         [else (cannot-synth ctx expr)])]))
```

We can check **tautologies** (formulas that can be proved with an empty context) by using the type-synth with an empty context          
```Scheme 
(require test-engine/racket-tests)
 
(define (check-proof p) (type-synth empty (parse-expr p)) true)
 
(check-expect (check-proof '((λ x => (λ y => x)) : (A -> (B -> A))))
              true)
```

## Chapter 2.6 - Assitance with proofs

We introduce the notion of holes (or goals) which are unfinished parts of the proof represented by `?`          


## Chapter 2.7 - Adding the connectives
conjunction type checking:
$$\frac{ \Gamma\vdash t\Leftarrow T ~~\Gamma\vdash w\Leftarrow W}
  {\Gamma\vdash\land_\mathit{intro}~t~w\Leftarrow T\land W} (\land_I)$$

conjunction type synthesis: 
$$\frac{ \Gamma\vdash t\Rightarrow T ~~\Gamma\vdash w\Rightarrow W}
  {\Gamma\vdash\land_\mathit{intro}~t~w\Rightarrow T\land W} (\land_I)$$

## Summary of rules

# Chapter 3 - Predicate Logic

## 3.1 - First-order logic
## 3.2 Higher-order logic
We will use higher-order logic for our development of proust
```
expr	=	 	(λ x => expr)
 	 	|	 	(expr expr)
 	 	|	 	(expr : expr)
 	 	|	 	x
 	 	|	 	(expr -> expr)
```
- types are no longer separate from terms

If a term can be synethesized to a valid Type, we say it is a **well-formed** type. This means we need to define a new structure to represent Type. 

```Scheme

(define (type-check ctx expr type)
  (match expr
    [(Lam x t)
       (type-check ctx type (Type))
       (match type
         [(Arrow tt tw) (type-check (cons `(,x ,tt) ctx) t tw)]
         [else (cannot-check ctx expr type)])]
    [else (if (equal? (type-synth ctx expr) type) true (cannot-check ctx expr type))]))
 
(define (type-synth ctx expr)
  (match expr
    [(Lam _ _) (cannot-synth ctx expr)]
    [(Ann e t) (type-check ctx e t) t]
    [(App f a)
       (define tf (type-synth ctx f))
        (match tf
         [(Arrow tt tw) #:when (type-check ctx a tt) tw]
         [else (cannot-synth ctx expr)])]
    [(Arrow tt tw)
       (type-check ctx tt (Type))
       (type-check ctx tw (Type))
       (Type)]
    [(? symbol? x)
       (cond
         [(assoc x ctx) => second]
         [else (Type)])]))
```

- here are the new type checking and type synthesis functions

## 3.2.1 - Universal quantification
A proof of $\forall (X:T) \ra W$ is a construction which permits us to transform an object $x$
of type $T$ into a proof of  $W[X\mapsto x]$
- if $W$ does not contain any $X$ then this is the become the rule for implication. So implication is just a special case of for-all.

A change to our earlier notion of lambda is that the type depends on the value of the argument. 
$$
\ir{(\forall_\mathit{wf})}
 {\Gamma\vdash T\La\mathit{Type} ~~~ \Gamma,x:T\vdash W\La\mathit{Type}}
 {\Gamma\vdash\forall (x:T)\ra W \La \mathit{Type}}
$$
$$
\ir{(\forall_{I})}
 {\Gamma\vdash \forall (x:T)\ra W \La\mathit{Type} ~~~ \Gamma,x: T\vdash t\La W}
 {\Gamma\vdash\la x.t\La\forall (x:T)\ra W}
$$

For-all elimnation: 
$$\ir{(\forall_{E})}
{\Gamma\vdash f\Ra\forall (x:T)\ra W ~~~ \Gamma\vdash t\La T}
{\Gamma\vdash f~t\Ra W[x\mapsto t]}$$_

We need Type to typecheck to Type since (T : Type) , then Type must also have a type
- this causes inconsistent logic, but for our purposes it will work as the solution will be a distraction for now
 So we have $\forall (T : Type) \ra (T \ra T)$
 - this is a **polymorphic** identity function since it applies to all T




























    







